# Spanish_translation_A-B_Test

Spanish Translation A/B Test

Data: 	user_table.csv, test_table.csv	

Notebook: spanishTest.ipynb

The data is from a worldwide e-commerce site with localized versions of the site.

A data scientist at company noticed that Spain-based users have a much higher conversion rate than any other Spanish-speaking country. She therefore went and talked to the international team in charge of Spain And LatAm to see if they had any ideas about why that was happening.
Spain and LatAm country manager suggested that one reason could be translation. All Spanish- speaking countries had the same translation of the site which was written by a Spaniard. They agreed to try a test where each country would have its one translation written by a local. That is, Argentinian users would see a translation written by an Argentinian, Mexican users by a Mexican and so on. Obviously, nothing would change for users from Spain.

After they run the test however, they are really surprised cause the test is negative. I.e., it appears that the non-localized translation was doing better!

In this data challenge:

. The test was confirmed  actually negative

. Explained why that might be happening

. Developed an algorithm to validate A/B test result
